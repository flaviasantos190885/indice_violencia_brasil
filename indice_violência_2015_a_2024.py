# -*- coding: utf-8 -*-
"""Indice Violência 2015 a 2024

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dDp-Sn4wLO6lkX3DH4p60E5tm7l08b3K

#Índice de Violência - 2015 a 2024

##Instalações e Importações
"""

!pip install pandas numpy plotly
!pip install dash dash-core-components dash-html-components dash-table
!pip install tensorflow
!pip install keras
!pip install scikit-learn

import pandas as pd
import numpy as np
import plotly.express as px
from google.colab import drive
from dash import Dash, dcc, html, Input, Output, dash_table

"""##Dados

###Conversão
"""

# Mountar Google Drive
drive.mount('/content/drive')

# Arquivos de 2015 até 2025
file_paths = [
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2015.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2016.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2017.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2018.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2019.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2020.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2021.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2022.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2023.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2024.xlsx",
    # "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2025.xlsx"
]

# Ler todos os arquivos e concatenar
dataframes = [pd.read_excel(path) for path in file_paths]
df_completo = pd.concat(dataframes, ignore_index=True)

# Salvar o DataFrame completo como CSV (sem limite de linhas)
df_completo.to_csv("/content/BancoVDE_2015_2024_Completo.csv", index=False, encoding="utf-8-sig")
print("Todos os arquivos foram salvos.")

# Carregar o arquivo CSV
df_completo = pd.read_csv('/content/BancoVDE_2015_2024_Completo.csv')

print(df_completo.head(100))

"""###Tratamento

Copia - df_completo
"""

#Criar uma cópia do DataFrame original
df_copia = df_completo.copy()

print(df_copia.head(1000))

# Adiciona colunas de Ano e Mês
df_copia['data_referencia'] = pd.to_datetime(df_copia['data_referencia'])
df_copia['Ano'] = df_copia['data_referencia'].dt.year
df_copia['Mes'] = df_copia['data_referencia'].dt.month_name()

# Traduz nomes dos meses
meses_pt = {
    'January': 'Janeiro', 'February': 'Fevereiro', 'March': 'Março', 'April': 'Abril',
    'May': 'Maio', 'June': 'Junho', 'July': 'Julho', 'August': 'Agosto',
    'September': 'Setembro', 'October': 'Outubro', 'November': 'Novembro', 'December': 'Dezembro'
}
df_copia['Mes'] = df_copia['Mes'].map(meses_pt)

print(df_copia.head(1000))

# Contar os valores únicos na coluna 'arma'
contagem = df_copia['arma'].value_counts(normalize=True, dropna=False)

# Exibir os nomes como lista
lista_armas = contagem.index.tolist()
print("Armas encontradas:", lista_armas)

# Exibir a proporção de cada uma (em porcentagem)
print("\nProporção de cada arma:")
print((contagem * 100).round(2).astype(str) + '%')

# Substitui espaços vazios por NaN (caso existam)
df_copia['arma'] = df_copia['arma'].replace(r'^\s*$', np.nan, regex=True)

# Calcula a distribuição (ignorando NaN)
proporcao_armas = df_copia['arma'].value_counts(normalize=True, dropna=True)

# Remove 'Metralhadora' e 'Submetralhadora' da distribuição usada para preencher os NaN
proporcao_filtrada = proporcao_armas.drop(['Metralhadora', 'Submetralhadora'], errors='ignore')

# Recalcula as proporções para somarem 100% (já que removemos categorias)
proporcao_normalizada = proporcao_filtrada / proporcao_filtrada.sum()

# Verifica quantos valores faltantes há
arma_faltantes = df_copia['arma'].isna()
num_faltantes = arma_faltantes.sum()

# Sorteia armas proporcionalmente (sem incluir metralhadoras)
arma_sorteadas = np.random.choice(
    proporcao_normalizada.index,
    size=num_faltantes,
    replace=True,
    p=proporcao_normalizada.values
)

# Preenche os valores NaN com os valores sorteados
df_copia.loc[arma_faltantes, 'arma'] = arma_sorteadas

print(df_copia['arma'].value_counts(normalize=True) * 100)

coluna = 'faixa_etaria'

# Verifica se há valores não nulos para calcular proporções
valores_validos = df_copia[coluna].dropna()

if not valores_validos.empty:
    proporcoes = valores_validos.value_counts(normalize=True)
    num_nans = df_copia[coluna].isna().sum()

    # Gera os novos valores com base nas proporções
    valores_preenchimento = np.random.choice(
        proporcoes.index,
        size=num_nans,
        p=proporcoes.values
    )

    # Preenche os NaNs
    df_copia.loc[df_copia[coluna].isna(), coluna] = valores_preenchimento

    # Verifica resultado
    print("Distribuição após preenchimento:")
    print(df_copia[coluna].value_counts(normalize=True))
else:
    print(f"A coluna '{coluna}' não tem valores suficientes para calcular proporções.")

#Filtrar apenas eventos abaixo
df_copia = df_copia[df_copia['evento'].isin(['Homicídio doloso', 'Feminicídio', 'Lesão corporal seguida de morte', 'Morte de Agente do Estado', 'Morte no trânsito ou em decorrência dele', 'Morte por intervenção de Agente do Estado', 'Mortes a esclarecer (sem indício de crime)', 'Roubo seguido de morte (latrocínio)', 'Suicídio', 'Suicídio de Agente do Estado'])]

#Excluir as colunas desnecessárias
colunas_excluir = ['agente', 'total', 'total_peso', 'abrangencia', 'formulario']
df_copia = df_copia.drop(columns=colunas_excluir, errors='ignore')

# 1. Valores únicos Municípios
valores_unicos = df_completo['municipio'].unique()
print("🔍 Valores únicos na coluna 'municipio':")
print(valores_unicos)

# 2. Contagem dos valores
print("\n📊 Contagem dos valores na coluna 'municipio':")
print(df_completo['municipio'].value_counts())

# 3. Valores diferentes de "NÃO INFORMADO"
valores_diferentes = [v for v in valores_unicos if v != 'NÃO INFORMADO']
print("\n✅ Valores diferentes de 'NÃO INFORMADO':")
print(valores_diferentes)

# Remove as linhas onde o município é "NÃO INFORMADO"
df_copia = df_copia[df_copia['municipio'] != 'NÃO INFORMADO']

# Verificação opcional: mostra os municípios restantes
print("Valores únicos restantes na coluna 'municipio':")
print(df_copia['municipio'].unique())

# Contar valores NaN por coluna
nan_por_coluna = df_copia.isna().sum()
print(nan_por_coluna)

# Converte para numérico com tratamento de erro
df_copia[['feminino', 'masculino', 'nao_informado']] = df_copia[['feminino', 'masculino', 'nao_informado']].apply(pd.to_numeric, errors='coerce')

# Substitui NaN por 0 e converte para inteiro
df_copia[['feminino', 'masculino', 'nao_informado']] = df_copia[['feminino', 'masculino', 'nao_informado']].fillna(0).astype(int)

# Agora calcula total_vitima com essas colunas já limpas
df_copia['total_vitima'] = (
    df_copia['feminino'] +
    df_copia['masculino'] +
    df_copia['nao_informado']
)

# Remove as linhas onde total_vitima == 0
df_copia = df_copia[df_copia['total_vitima'] != 0]

# Contar valores NaN por coluna
nan_por_coluna = df_copia.isna().sum()
print(nan_por_coluna)

print(df_copia.head(1000))

# Verifica como ficou em linhas e colunas
print(df_copia.shape)

# Salvar o DataFrame filtrado em um arquivo CSV com o nome desejado
df_copia.to_csv("Dados_2015_2024.csv", index=False)

"""##Gráficos"""

# ========== Carregamento e pré-processamento ==========
df = pd.read_csv("Dados_2015_2024.csv")
df['data_referencia'] = pd.to_datetime(df['data_referencia'])
df['Ano'] = df['data_referencia'].dt.year

# Create a dictionary to map English month names to Portuguese month names
meses_en_pt = {
    'January': 'Janeiro', 'February': 'Fevereiro', 'March': 'Março', 'April': 'Abril',
    'May': 'Maio', 'June': 'Junho', 'July': 'Julho', 'August': 'Agosto',
    'September': 'Setembro', 'October': 'Outubro', 'November': 'Novembro', 'December': 'Dezembro'
}

# Get the month name in English and then map it to Portuguese
df['Mes'] = df['data_referencia'].dt.month_name().map(meses_en_pt)


# Ordenação de meses
ordem_meses = ['Janeiro', 'Fevereiro', 'Março', 'Abril', 'Maio', 'Junho',
               'Julho', 'Agosto', 'Setembro', 'Outubro', 'Novembro', 'Dezembro']
df['Mes'] = pd.Categorical(df['Mes'], categories=ordem_meses, ordered=True)

# ========== App ==========
app = Dash(__name__)
app.title = "Dashboard de Homicídios e Feminicídios"

app.layout = html.Div([
    html.H2("Filtros", style={'textAlign': 'center', 'marginBottom': '20px'}),

    html.Div([
        html.Div([
            html.Label("Ano"),
            dcc.Dropdown(
                df['Ano'].sort_values().unique(), 2019,
                id='filtro_ano', placeholder='Ano'
            )
        ], style={'width': '10%', 'minWidth': '150px'}),

        html.Div([
            html.Label("Estado"),
            dcc.Dropdown(
                df['uf'].sort_values().unique(), multi=True,
                id='filtro_estado', placeholder='Estados'
            )
        ], style={'width': '10%', 'minWidth': '150px'}),

        html.Div([
            html.Label("Cidade"),
            dcc.Dropdown(
                ['Todos'] + sorted(df['municipio'].dropna().unique()),
                'Todos', id='filtro_cidade'
            )
        ], style={'width': '10%', 'minWidth': '150px'}),

        html.Div([
            html.Label("Evento"),
            dcc.Dropdown(
                ['Todos'] + sorted(df['evento'].dropna().unique()),
                'Todos', id='filtro_evento'
            )
        ], style={'width': '10%', 'minWidth': '150px'}),

        html.Div([
            html.Label("Faixa Etária"),
            dcc.Dropdown(
                ['Todas'] + sorted(df['faixa_etaria'].dropna().unique()),
                'Todas', id='filtro_faixa'
            )
        ], style={'width': '10%', 'minWidth': '150px'}),

        html.Div([
            html.Label("Arma"),
            dcc.Dropdown(
                ['Todas'] + sorted(df['arma'].dropna().unique()),
                'Todas', id='filtro_arma'
            )
        ], style={'width': '10%', 'minWidth': '150px'})
    ], style={
        'display': 'flex',
        'flexWrap': 'wrap',
        'gap': '10px',
        'justifyContent': 'center',
        'marginBottom': '30px'
    }),

    dcc.Graph(id='grafico_barra'),
    dcc.Graph(id='grafico_linha'),
    dcc.Graph(id='grafico_pizza'),

    html.H3("Tabela de Dados Filtrados"),
    dash_table.DataTable(
        id='tabela_dados',
        page_size=10,
        style_table={'overflowX': 'auto'}
    )
])


@app.callback(
    [Output('grafico_barra', 'figure'),
     Output('grafico_linha', 'figure'),
     Output('grafico_pizza', 'figure'),
     Output('tabela_dados', 'data'),
     Output('tabela_dados', 'columns')],
    [Input('filtro_ano', 'value'),
     Input('filtro_estado', 'value'),
     Input('filtro_cidade', 'value'),
     Input('filtro_evento', 'value'),
     Input('filtro_faixa', 'value'),
     Input('filtro_arma', 'value')]
)
def atualizar_graficos(ano, estados, cidade, evento, faixa, arma):
    df_filt = df[df['Ano'] == ano]

    if estados:
        df_filt = df_filt[df_filt['uf'].isin(estados)]

    if cidade != "Todos":
        df_filt = df_filt[df_filt['municipio'] == cidade]

    if evento != "Todos":
        df_filt = df_filt[df_filt['evento'] == evento]

    if faixa != "Todas":
        df_filt = df_filt[df_filt['faixa_etaria'] == faixa]

    if arma != "Todas":
        df_filt = df_filt[df_filt['arma'] == arma]

    # Gráfico de barras
    df_bar = df_filt.groupby('uf')['total_vitima'].sum().reset_index()
    fig_bar = px.bar(df_bar, x='uf', y='total_vitima', text='total_vitima',
                     color='uf', title='Total de Vítimas por Estado')

    # Gráfico de linha
    df_linha = df_filt.groupby(['uf', 'Mes'])['total_vitima'].sum().reset_index()
    fig_linha = px.line(df_linha, x='Mes', y='total_vitima', color='uf',
                        markers=True, title='Evolução Mensal dos Casos por Estado')

    # Gráfico de pizza
    df_pizza = df_filt.groupby('arma').size().reset_index(name='quantidade')
    if not df_pizza.empty:
        fig_pizza = px.pie(df_pizza, names='arma', values='quantidade',
                           hole=0.4, title='Distribuição de Tipos de Arma')
    else:
        fig_pizza = px.pie(title="Sem dados para gráfico de pizza")

    # Tabela
    df_tab = df_filt[(df_filt['feminino'] >= 1) | (df_filt['masculino'] >= 1) | (df_filt['nao_informado'] >= 1)]
    df_tab = df_tab.copy()
    df_tab['data_referencia'] = df_tab['data_referencia'].dt.strftime('%d-%m-%Y')

    colunas_numericas = df_tab.select_dtypes(include='number')
    colunas_validas = colunas_numericas.columns[colunas_numericas.sum() > 0]
    df_final = pd.concat([df_tab.select_dtypes(exclude='number'), df_tab[colunas_validas]], axis=1)

    colunas = [{"name": col, "id": col} for col in df_final.columns]

    return fig_bar, fig_linha, fig_pizza, df_final.to_dict('records'), colunas


if __name__ == '__main__':
    app.run(debug=True)

"""##Previsões

###Multivalorado
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import GRU, Dense, Dropout
from tensorflow.keras.callbacks import ModelCheckpoint
import joblib

print("--- INICIANDO A CRIAÇÃO DO MODELO MULTIVARIADO (VERSÃO OTIMIZADA) ---")

# --- 1. CARREGAMENTO E PREPARAÇÃO INICIAL DOS DADOS ---
try:
    df = pd.read_csv("Dados_2015_2024.csv")
    df['data_referencia'] = pd.to_datetime(df['data_referencia'])
    df = df.sort_values('data_referencia').reset_index(drop=True)
except FileNotFoundError:
    print("\n❌ ERRO: Arquivo 'Dados_2015_2024.csv' não encontrado.")
    exit()

# Separa a variável alvo (y) das variáveis de features (X)
y_df = df[['total_vitima']]

# MODIFICAÇÃO PRINCIPAL: REMOVER A COLUNA 'municipio' ANTES DO TREINAMENTO
print("Removendo a coluna 'municipio' para otimizar o uso de memória...")
X_df = df.drop(columns=['total_vitima', 'data_referencia', 'municipio']) # <-- MUNICÍPIO REMOVIDO AQUI

# --- 2. PRÉ-PROCESSAMENTO E FEATURE ENGINEERING ---
colunas_categoricas = X_df.select_dtypes(include=['object', 'category']).columns
colunas_numericas = X_df.select_dtypes(include=np.number).columns

print(f"\nColunas Categóricas para transformar: {list(colunas_categoricas)}")

preprocessor = ColumnTransformer(
    transformers=[
        ('num', MinMaxScaler(), colunas_numericas),
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), colunas_categoricas)
    ],
    remainder='passthrough'
)

print("\nAplicando pré-processamento (OneHotEncoding e Scaler)...")
X_processed = preprocessor.fit_transform(X_df)

y_scaler = MinMaxScaler()
y_processed = y_scaler.fit_transform(y_df)

print(f"Shape dos dados de treino após transformação: {X_processed.shape}")

# --- 3. CRIAÇÃO DAS SEQUÊNCIAS PARA A REDE NEURAL ---
janela = 10
X_seq, y_seq = [], []

print(f"\nCriando sequências de dados com janela de {janela} eventos...")
for i in range(janela, len(X_processed)):
    X_seq.append(X_processed[i-janela:i])
    y_seq.append(y_processed[i])

X_seq = np.array(X_seq)
y_seq = np.array(y_seq)

print(f"Shape final dos dados de entrada do modelo (X): {X_seq.shape}")

# --- 4. CONSTRUÇÃO E TREINAMENTO DO MODELO GRU ---
n_features = X_seq.shape[2]
model = Sequential([
    GRU(units=100, return_sequences=True, input_shape=(janela, n_features)),
    Dropout(0.2),
    GRU(units=50),
    Dropout(0.2),
    Dense(units=25, activation='relu'),
    Dense(units=1)
])
model.compile(optimizer='adam', loss='mean_squared_error')
model.summary()

filepath_modelo = 'melhor_modelo_multivariado.keras'
checkpoint = ModelCheckpoint(filepath_modelo, monitor='val_loss', save_best_only=True, mode='min', verbose=1)

print("\n--- INICIANDO TREINAMENTO DO MODELO MULTIVARIADO ---")
model.fit(X_seq, y_seq, epochs=1, batch_size=32, callbacks=[checkpoint], validation_split=0.1, verbose=1)

# --- 5. SALVANDO OS COMPONENTES FINAIS ---
joblib.dump(preprocessor, 'preprocessor.joblib')
joblib.dump(y_scaler, 'y_scaler.joblib')

print("\n--- PROCESSO CONCLUÍDO ---")
print(f"✅ Melhor modelo salvo em: '{filepath_modelo}'")
print(f"✅ Pré-processador de dados salvo em: 'preprocessor.joblib'")
print(f"✅ Normalizador da variável alvo salvo em: 'y_scaler.joblib'")

import numpy as np
import pandas as pd
import joblib
from tensorflow.keras.models import load_model
import warnings

# Suprimir avisos de formatação do pandas que podem poluir a saída
warnings.filterwarnings("ignore", category=FutureWarning)

# --- 1. CARREGAR O MODELO E OS COMPONENTES SALVOS ---
print("--- Carregando modelo e componentes de previsão ---")
try:
    model = load_model('melhor_modelo_multivariado.keras')
    preprocessor = joblib.load('preprocessor.joblib')
    y_scaler = joblib.load('y_scaler.joblib')
    df = pd.read_csv("Dados_2015_2024.csv")
    df['data_referencia'] = pd.to_datetime(df['data_referencia'])
    df = df.sort_values('data_referencia').reset_index(drop=True)
    print("✅ Modelo e componentes carregados com sucesso.")
except FileNotFoundError as e:
    print(f"\n❌ ERRO: Arquivo não encontrado. Certifique-se que o arquivo '{e.filename}' está no diretório.")
    exit()

# --- 2. FUNÇÃO AUXILIAR PARA OBTER INPUTS (sem alterações) ---
def obter_filtro_usuario(df_local, nome_coluna, nome_amigavel):
    print(f"\n--- Filtro de {nome_amigavel} (Opcional) ---")
    print("Para não usar este filtro, apenas pressione Enter.")
    opcoes = sorted(df_local[nome_coluna].unique())
    if len(opcoes) > 15:
        print(f"(Mostrando as primeiras 15 de {len(opcoes)} opções)")
        for i, opcao in enumerate(opcoes[:15]): print(f"[{i+1}] {opcao}")
        print("...")
    else:
        for i, opcao in enumerate(opcoes): print(f"[{i+1}] {opcao}")
    while True:
        escolha = input(f"Digite o NÚMERO, NOME exato, ou deixe em branco para pular: ")
        if not escolha: return None
        try:
            if 0 <= int(escolha) - 1 < len(opcoes): return opcoes[int(escolha) - 1]
        except ValueError:
            if escolha in opcoes: return escolha
        print("Opção inválida.")

# --- 3. LÓGICA DE PREVISÃO INTERATIVA (FLUXO CORRIGIDO) ---
while True:
    print("\n\n--- NOVA PREVISÃO ANUAL ESTIMADA ---")

    # ETAPA 1: PEDIR O ANO (OBRIGATÓRIO)
    while True:
        try:
            ano_desejado = int(input("\nDigite o ANO para a previsão (Obrigatório, ex: 2026): "))
            if ano_desejado > df['Ano'].max():
                break
            else:
                print(f"Por favor, digite um ano futuro, maior que {df['Ano'].max()}.")
        except ValueError:
            print("Entrada inválida. Por favor, digite um número inteiro.")

    # ETAPA 2: PEDIR OS FILTROS (OPCIONAIS)
    df_filtrado = df.copy()
    filtros_aplicados = {}
    colunas_para_filtrar = ['uf', 'evento', 'arma', 'faixa_etaria']
    for coluna in colunas_para_filtrar:
        escolha = obter_filtro_usuario(df_filtrado, coluna, coluna.replace('_', ' ').title())
        if escolha:
            filtros_aplicados[coluna] = escolha
            df_filtrado = df_filtrado[df_filtrado[coluna] == escolha]

    # ETAPA 3: PREPARAR DADOS E FAZER A PREVISÃO
    janela = 10
    if len(df_filtrado) < janela:
        print(f"\n❌ ERRO: Não há dados históricos suficientes ({len(df_filtrado)} eventos) para o cenário escolhido.")
    else:
        # Calcular a média de eventos por ano para o cenário filtrado
        num_anos_historico = df_filtrado['Ano'].nunique()
        media_eventos_ano = len(df_filtrado) / num_anos_historico if num_anos_historico > 0 else 0

        # Montar a sequência de entrada para o modelo
        # Pegamos os últimos 9 eventos reais e criamos um 10º evento "fictício" no ano desejado
        sequencia_base = df_filtrado.tail(janela - 1).copy()
        evento_futuro_template = df_filtrado.tail(1).copy()
        evento_futuro_template['Ano'] = ano_desejado

        sequencia_final_df = pd.concat([sequencia_base, evento_futuro_template], ignore_index=True)

        # Preparar os dados para o modelo usando o preprocessor carregado
        X_para_prever = sequencia_final_df.drop(columns=['total_vitima', 'data_referencia', 'municipio'])
        X_processado = preprocessor.transform(X_para_prever)
        X_final = np.reshape(X_processado, (1, X_processado.shape[0], X_processado.shape[1]))

        # Fazer a previsão para um evento típico no futuro
        previsao_evento_normalizada = model.predict(X_final)
        previsao_evento_real = y_scaler.inverse_transform(previsao_evento_normalizada)
        vitimas_por_evento = np.ceil(previsao_evento_real[0][0])

        # Calcular o total anual estimado
        previsao_anual_total = vitimas_por_evento * media_eventos_ano

        # ETAPA 4: MOSTRAR O RESULTADO FINAL
        print("\n-------------------------------------------")
        print("Cenário da Previsão:")
        print(f"- Ano Previsto: {ano_desejado}")
        for nome, valor in filtros_aplicados.items():
            print(f"- {nome.title()}: {valor}")
        if not filtros_aplicados:
            print("- Nenhum filtro adicional (cenário geral).")

        print("\n🎯 PREVISÃO ANUAL ESTIMADA:")
        print(f"O total de vítimas estimado para o ano de {ano_desejado} neste cenário é de: {int(previsao_anual_total)}")
        print("-------------------------------------------")
        print(f"(Nota: Estimativa baseada em uma previsão de {int(vitimas_por_evento)} vítimas por evento, multiplicada pela média de {media_eventos_ano:.1f} eventos por ano para este cenário).")

    if input("\nDeseja fazer uma nova previsão? (s/n): ").lower() != 's':
        break

print("\nScript de previsão finalizado.")