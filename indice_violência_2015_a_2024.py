# -*- coding: utf-8 -*-
"""Indice Viol√™ncia 2015 a 2024

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dDp-Sn4wLO6lkX3DH4p60E5tm7l08b3K

#√çndice de Viol√™ncia - 2015 a 2024

##Instala√ß√µes e Importa√ß√µes
"""

!pip install pandas numpy plotly
!pip install dash dash-core-components dash-html-components dash-table
!pip install tensorflow
!pip install keras
!pip install scikit-learn

import pandas as pd
import numpy as np
import plotly.express as px
from google.colab import drive
from dash import Dash, dcc, html, Input, Output, dash_table

"""##Dados

###Convers√£o
"""

# Mountar Google Drive
drive.mount('/content/drive')

# Arquivos de 2015 at√© 2025
file_paths = [
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2015.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2016.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2017.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2018.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2019.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2020.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2021.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2022.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2023.xlsx",
    "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2024.xlsx",
    # "/content/drive/MyDrive/TCC/TCC Final/dados/BancoVDE 2025.xlsx"
]

# Ler todos os arquivos e concatenar
dataframes = [pd.read_excel(path) for path in file_paths]
df_completo = pd.concat(dataframes, ignore_index=True)

# Salvar o DataFrame completo como CSV (sem limite de linhas)
df_completo.to_csv("/content/BancoVDE_2015_2024_Completo.csv", index=False, encoding="utf-8-sig")
print("Todos os arquivos foram salvos.")

# Carregar o arquivo CSV
df_completo = pd.read_csv('/content/BancoVDE_2015_2024_Completo.csv')

print(df_completo.head(100))

"""###Tratamento

Copia - df_completo
"""

#Criar uma c√≥pia do DataFrame original
df_copia = df_completo.copy()

print(df_copia.head(1000))

# Adiciona colunas de Ano e M√™s
df_copia['data_referencia'] = pd.to_datetime(df_copia['data_referencia'])
df_copia['Ano'] = df_copia['data_referencia'].dt.year
df_copia['Mes'] = df_copia['data_referencia'].dt.month_name()

# Traduz nomes dos meses
meses_pt = {
    'January': 'Janeiro', 'February': 'Fevereiro', 'March': 'Mar√ßo', 'April': 'Abril',
    'May': 'Maio', 'June': 'Junho', 'July': 'Julho', 'August': 'Agosto',
    'September': 'Setembro', 'October': 'Outubro', 'November': 'Novembro', 'December': 'Dezembro'
}
df_copia['Mes'] = df_copia['Mes'].map(meses_pt)

print(df_copia.head(1000))

# Contar os valores √∫nicos na coluna 'arma'
contagem = df_copia['arma'].value_counts(normalize=True, dropna=False)

# Exibir os nomes como lista
lista_armas = contagem.index.tolist()
print("Armas encontradas:", lista_armas)

# Exibir a propor√ß√£o de cada uma (em porcentagem)
print("\nPropor√ß√£o de cada arma:")
print((contagem * 100).round(2).astype(str) + '%')

# Substitui espa√ßos vazios por NaN (caso existam)
df_copia['arma'] = df_copia['arma'].replace(r'^\s*$', np.nan, regex=True)

# Calcula a distribui√ß√£o (ignorando NaN)
proporcao_armas = df_copia['arma'].value_counts(normalize=True, dropna=True)

# Remove 'Metralhadora' e 'Submetralhadora' da distribui√ß√£o usada para preencher os NaN
proporcao_filtrada = proporcao_armas.drop(['Metralhadora', 'Submetralhadora'], errors='ignore')

# Recalcula as propor√ß√µes para somarem 100% (j√° que removemos categorias)
proporcao_normalizada = proporcao_filtrada / proporcao_filtrada.sum()

# Verifica quantos valores faltantes h√°
arma_faltantes = df_copia['arma'].isna()
num_faltantes = arma_faltantes.sum()

# Sorteia armas proporcionalmente (sem incluir metralhadoras)
arma_sorteadas = np.random.choice(
    proporcao_normalizada.index,
    size=num_faltantes,
    replace=True,
    p=proporcao_normalizada.values
)

# Preenche os valores NaN com os valores sorteados
df_copia.loc[arma_faltantes, 'arma'] = arma_sorteadas

print(df_copia['arma'].value_counts(normalize=True) * 100)

coluna = 'faixa_etaria'

# Verifica se h√° valores n√£o nulos para calcular propor√ß√µes
valores_validos = df_copia[coluna].dropna()

if not valores_validos.empty:
    proporcoes = valores_validos.value_counts(normalize=True)
    num_nans = df_copia[coluna].isna().sum()

    # Gera os novos valores com base nas propor√ß√µes
    valores_preenchimento = np.random.choice(
        proporcoes.index,
        size=num_nans,
        p=proporcoes.values
    )

    # Preenche os NaNs
    df_copia.loc[df_copia[coluna].isna(), coluna] = valores_preenchimento

    # Verifica resultado
    print("Distribui√ß√£o ap√≥s preenchimento:")
    print(df_copia[coluna].value_counts(normalize=True))
else:
    print(f"A coluna '{coluna}' n√£o tem valores suficientes para calcular propor√ß√µes.")

#Filtrar apenas eventos abaixo
df_copia = df_copia[df_copia['evento'].isin(['Homic√≠dio doloso', 'Feminic√≠dio', 'Les√£o corporal seguida de morte', 'Morte de Agente do Estado', 'Morte no tr√¢nsito ou em decorr√™ncia dele', 'Morte por interven√ß√£o de Agente do Estado', 'Mortes a esclarecer (sem ind√≠cio de crime)', 'Roubo seguido de morte (latroc√≠nio)', 'Suic√≠dio', 'Suic√≠dio de Agente do Estado'])]

#Excluir as colunas desnecess√°rias
colunas_excluir = ['agente', 'total', 'total_peso', 'abrangencia', 'formulario']
df_copia = df_copia.drop(columns=colunas_excluir, errors='ignore')

# 1. Valores √∫nicos Munic√≠pios
valores_unicos = df_completo['municipio'].unique()
print("üîç Valores √∫nicos na coluna 'municipio':")
print(valores_unicos)

# 2. Contagem dos valores
print("\nüìä Contagem dos valores na coluna 'municipio':")
print(df_completo['municipio'].value_counts())

# 3. Valores diferentes de "N√ÉO INFORMADO"
valores_diferentes = [v for v in valores_unicos if v != 'N√ÉO INFORMADO']
print("\n‚úÖ Valores diferentes de 'N√ÉO INFORMADO':")
print(valores_diferentes)

# Remove as linhas onde o munic√≠pio √© "N√ÉO INFORMADO"
df_copia = df_copia[df_copia['municipio'] != 'N√ÉO INFORMADO']

# Verifica√ß√£o opcional: mostra os munic√≠pios restantes
print("Valores √∫nicos restantes na coluna 'municipio':")
print(df_copia['municipio'].unique())

# Contar valores NaN por coluna
nan_por_coluna = df_copia.isna().sum()
print(nan_por_coluna)

# Converte para num√©rico com tratamento de erro
df_copia[['feminino', 'masculino', 'nao_informado']] = df_copia[['feminino', 'masculino', 'nao_informado']].apply(pd.to_numeric, errors='coerce')

# Substitui NaN por 0 e converte para inteiro
df_copia[['feminino', 'masculino', 'nao_informado']] = df_copia[['feminino', 'masculino', 'nao_informado']].fillna(0).astype(int)

# Agora calcula total_vitima com essas colunas j√° limpas
df_copia['total_vitima'] = (
    df_copia['feminino'] +
    df_copia['masculino'] +
    df_copia['nao_informado']
)

# Remove as linhas onde total_vitima == 0
df_copia = df_copia[df_copia['total_vitima'] != 0]

# Contar valores NaN por coluna
nan_por_coluna = df_copia.isna().sum()
print(nan_por_coluna)

print(df_copia.head(1000))

# Verifica como ficou em linhas e colunas
print(df_copia.shape)

# Salvar o DataFrame filtrado em um arquivo CSV com o nome desejado
df_copia.to_csv("Dados_2015_2024.csv", index=False)

"""##Gr√°ficos"""

# ========== Carregamento e pr√©-processamento ==========
df = pd.read_csv("Dados_2015_2024.csv")
df['data_referencia'] = pd.to_datetime(df['data_referencia'])
df['Ano'] = df['data_referencia'].dt.year

# Create a dictionary to map English month names to Portuguese month names
meses_en_pt = {
    'January': 'Janeiro', 'February': 'Fevereiro', 'March': 'Mar√ßo', 'April': 'Abril',
    'May': 'Maio', 'June': 'Junho', 'July': 'Julho', 'August': 'Agosto',
    'September': 'Setembro', 'October': 'Outubro', 'November': 'Novembro', 'December': 'Dezembro'
}

# Get the month name in English and then map it to Portuguese
df['Mes'] = df['data_referencia'].dt.month_name().map(meses_en_pt)


# Ordena√ß√£o de meses
ordem_meses = ['Janeiro', 'Fevereiro', 'Mar√ßo', 'Abril', 'Maio', 'Junho',
               'Julho', 'Agosto', 'Setembro', 'Outubro', 'Novembro', 'Dezembro']
df['Mes'] = pd.Categorical(df['Mes'], categories=ordem_meses, ordered=True)

# ========== App ==========
app = Dash(__name__)
app.title = "Dashboard de Homic√≠dios e Feminic√≠dios"

app.layout = html.Div([
    html.H2("Filtros", style={'textAlign': 'center', 'marginBottom': '20px'}),

    html.Div([
        html.Div([
            html.Label("Ano"),
            dcc.Dropdown(
                df['Ano'].sort_values().unique(), 2019,
                id='filtro_ano', placeholder='Ano'
            )
        ], style={'width': '10%', 'minWidth': '150px'}),

        html.Div([
            html.Label("Estado"),
            dcc.Dropdown(
                df['uf'].sort_values().unique(), multi=True,
                id='filtro_estado', placeholder='Estados'
            )
        ], style={'width': '10%', 'minWidth': '150px'}),

        html.Div([
            html.Label("Cidade"),
            dcc.Dropdown(
                ['Todos'] + sorted(df['municipio'].dropna().unique()),
                'Todos', id='filtro_cidade'
            )
        ], style={'width': '10%', 'minWidth': '150px'}),

        html.Div([
            html.Label("Evento"),
            dcc.Dropdown(
                ['Todos'] + sorted(df['evento'].dropna().unique()),
                'Todos', id='filtro_evento'
            )
        ], style={'width': '10%', 'minWidth': '150px'}),

        html.Div([
            html.Label("Faixa Et√°ria"),
            dcc.Dropdown(
                ['Todas'] + sorted(df['faixa_etaria'].dropna().unique()),
                'Todas', id='filtro_faixa'
            )
        ], style={'width': '10%', 'minWidth': '150px'}),

        html.Div([
            html.Label("Arma"),
            dcc.Dropdown(
                ['Todas'] + sorted(df['arma'].dropna().unique()),
                'Todas', id='filtro_arma'
            )
        ], style={'width': '10%', 'minWidth': '150px'})
    ], style={
        'display': 'flex',
        'flexWrap': 'wrap',
        'gap': '10px',
        'justifyContent': 'center',
        'marginBottom': '30px'
    }),

    dcc.Graph(id='grafico_barra'),
    dcc.Graph(id='grafico_linha'),
    dcc.Graph(id='grafico_pizza'),

    html.H3("Tabela de Dados Filtrados"),
    dash_table.DataTable(
        id='tabela_dados',
        page_size=10,
        style_table={'overflowX': 'auto'}
    )
])


@app.callback(
    [Output('grafico_barra', 'figure'),
     Output('grafico_linha', 'figure'),
     Output('grafico_pizza', 'figure'),
     Output('tabela_dados', 'data'),
     Output('tabela_dados', 'columns')],
    [Input('filtro_ano', 'value'),
     Input('filtro_estado', 'value'),
     Input('filtro_cidade', 'value'),
     Input('filtro_evento', 'value'),
     Input('filtro_faixa', 'value'),
     Input('filtro_arma', 'value')]
)
def atualizar_graficos(ano, estados, cidade, evento, faixa, arma):
    df_filt = df[df['Ano'] == ano]

    if estados:
        df_filt = df_filt[df_filt['uf'].isin(estados)]

    if cidade != "Todos":
        df_filt = df_filt[df_filt['municipio'] == cidade]

    if evento != "Todos":
        df_filt = df_filt[df_filt['evento'] == evento]

    if faixa != "Todas":
        df_filt = df_filt[df_filt['faixa_etaria'] == faixa]

    if arma != "Todas":
        df_filt = df_filt[df_filt['arma'] == arma]

    # Gr√°fico de barras
    df_bar = df_filt.groupby('uf')['total_vitima'].sum().reset_index()
    fig_bar = px.bar(df_bar, x='uf', y='total_vitima', text='total_vitima',
                     color='uf', title='Total de V√≠timas por Estado')

    # Gr√°fico de linha
    df_linha = df_filt.groupby(['uf', 'Mes'])['total_vitima'].sum().reset_index()
    fig_linha = px.line(df_linha, x='Mes', y='total_vitima', color='uf',
                        markers=True, title='Evolu√ß√£o Mensal dos Casos por Estado')

    # Gr√°fico de pizza
    df_pizza = df_filt.groupby('arma').size().reset_index(name='quantidade')
    if not df_pizza.empty:
        fig_pizza = px.pie(df_pizza, names='arma', values='quantidade',
                           hole=0.4, title='Distribui√ß√£o de Tipos de Arma')
    else:
        fig_pizza = px.pie(title="Sem dados para gr√°fico de pizza")

    # Tabela
    df_tab = df_filt[(df_filt['feminino'] >= 1) | (df_filt['masculino'] >= 1) | (df_filt['nao_informado'] >= 1)]
    df_tab = df_tab.copy()
    df_tab['data_referencia'] = df_tab['data_referencia'].dt.strftime('%d-%m-%Y')

    colunas_numericas = df_tab.select_dtypes(include='number')
    colunas_validas = colunas_numericas.columns[colunas_numericas.sum() > 0]
    df_final = pd.concat([df_tab.select_dtypes(exclude='number'), df_tab[colunas_validas]], axis=1)

    colunas = [{"name": col, "id": col} for col in df_final.columns]

    return fig_bar, fig_linha, fig_pizza, df_final.to_dict('records'), colunas


if __name__ == '__main__':
    app.run(debug=True)

"""##Previs√µes

###Multivalorado
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import GRU, Dense, Dropout
from tensorflow.keras.callbacks import ModelCheckpoint
import joblib

print("--- INICIANDO A CRIA√á√ÉO DO MODELO MULTIVARIADO (VERS√ÉO OTIMIZADA) ---")

# --- 1. CARREGAMENTO E PREPARA√á√ÉO INICIAL DOS DADOS ---
try:
    df = pd.read_csv("Dados_2015_2024.csv")
    df['data_referencia'] = pd.to_datetime(df['data_referencia'])
    df = df.sort_values('data_referencia').reset_index(drop=True)
except FileNotFoundError:
    print("\n‚ùå ERRO: Arquivo 'Dados_2015_2024.csv' n√£o encontrado.")
    exit()

# Separa a vari√°vel alvo (y) das vari√°veis de features (X)
y_df = df[['total_vitima']]

# MODIFICA√á√ÉO PRINCIPAL: REMOVER A COLUNA 'municipio' ANTES DO TREINAMENTO
print("Removendo a coluna 'municipio' para otimizar o uso de mem√≥ria...")
X_df = df.drop(columns=['total_vitima', 'data_referencia', 'municipio']) # <-- MUNIC√çPIO REMOVIDO AQUI

# --- 2. PR√â-PROCESSAMENTO E FEATURE ENGINEERING ---
colunas_categoricas = X_df.select_dtypes(include=['object', 'category']).columns
colunas_numericas = X_df.select_dtypes(include=np.number).columns

print(f"\nColunas Categ√≥ricas para transformar: {list(colunas_categoricas)}")

preprocessor = ColumnTransformer(
    transformers=[
        ('num', MinMaxScaler(), colunas_numericas),
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), colunas_categoricas)
    ],
    remainder='passthrough'
)

print("\nAplicando pr√©-processamento (OneHotEncoding e Scaler)...")
X_processed = preprocessor.fit_transform(X_df)

y_scaler = MinMaxScaler()
y_processed = y_scaler.fit_transform(y_df)

print(f"Shape dos dados de treino ap√≥s transforma√ß√£o: {X_processed.shape}")

# --- 3. CRIA√á√ÉO DAS SEQU√äNCIAS PARA A REDE NEURAL ---
janela = 10
X_seq, y_seq = [], []

print(f"\nCriando sequ√™ncias de dados com janela de {janela} eventos...")
for i in range(janela, len(X_processed)):
    X_seq.append(X_processed[i-janela:i])
    y_seq.append(y_processed[i])

X_seq = np.array(X_seq)
y_seq = np.array(y_seq)

print(f"Shape final dos dados de entrada do modelo (X): {X_seq.shape}")

# --- 4. CONSTRU√á√ÉO E TREINAMENTO DO MODELO GRU ---
n_features = X_seq.shape[2]
model = Sequential([
    GRU(units=100, return_sequences=True, input_shape=(janela, n_features)),
    Dropout(0.2),
    GRU(units=50),
    Dropout(0.2),
    Dense(units=25, activation='relu'),
    Dense(units=1)
])
model.compile(optimizer='adam', loss='mean_squared_error')
model.summary()

filepath_modelo = 'melhor_modelo_multivariado.keras'
checkpoint = ModelCheckpoint(filepath_modelo, monitor='val_loss', save_best_only=True, mode='min', verbose=1)

print("\n--- INICIANDO TREINAMENTO DO MODELO MULTIVARIADO ---")
model.fit(X_seq, y_seq, epochs=1, batch_size=32, callbacks=[checkpoint], validation_split=0.1, verbose=1)

# --- 5. SALVANDO OS COMPONENTES FINAIS ---
joblib.dump(preprocessor, 'preprocessor.joblib')
joblib.dump(y_scaler, 'y_scaler.joblib')

print("\n--- PROCESSO CONCLU√çDO ---")
print(f"‚úÖ Melhor modelo salvo em: '{filepath_modelo}'")
print(f"‚úÖ Pr√©-processador de dados salvo em: 'preprocessor.joblib'")
print(f"‚úÖ Normalizador da vari√°vel alvo salvo em: 'y_scaler.joblib'")

import numpy as np
import pandas as pd
import joblib
from tensorflow.keras.models import load_model
import warnings

# Suprimir avisos de formata√ß√£o do pandas que podem poluir a sa√≠da
warnings.filterwarnings("ignore", category=FutureWarning)

# --- 1. CARREGAR O MODELO E OS COMPONENTES SALVOS ---
print("--- Carregando modelo e componentes de previs√£o ---")
try:
    model = load_model('melhor_modelo_multivariado.keras')
    preprocessor = joblib.load('preprocessor.joblib')
    y_scaler = joblib.load('y_scaler.joblib')
    df = pd.read_csv("Dados_2015_2024.csv")
    df['data_referencia'] = pd.to_datetime(df['data_referencia'])
    df = df.sort_values('data_referencia').reset_index(drop=True)
    print("‚úÖ Modelo e componentes carregados com sucesso.")
except FileNotFoundError as e:
    print(f"\n‚ùå ERRO: Arquivo n√£o encontrado. Certifique-se que o arquivo '{e.filename}' est√° no diret√≥rio.")
    exit()

# --- 2. FUN√á√ÉO AUXILIAR PARA OBTER INPUTS (sem altera√ß√µes) ---
def obter_filtro_usuario(df_local, nome_coluna, nome_amigavel):
    print(f"\n--- Filtro de {nome_amigavel} (Opcional) ---")
    print("Para n√£o usar este filtro, apenas pressione Enter.")
    opcoes = sorted(df_local[nome_coluna].unique())
    if len(opcoes) > 15:
        print(f"(Mostrando as primeiras 15 de {len(opcoes)} op√ß√µes)")
        for i, opcao in enumerate(opcoes[:15]): print(f"[{i+1}] {opcao}")
        print("...")
    else:
        for i, opcao in enumerate(opcoes): print(f"[{i+1}] {opcao}")
    while True:
        escolha = input(f"Digite o N√öMERO, NOME exato, ou deixe em branco para pular: ")
        if not escolha: return None
        try:
            if 0 <= int(escolha) - 1 < len(opcoes): return opcoes[int(escolha) - 1]
        except ValueError:
            if escolha in opcoes: return escolha
        print("Op√ß√£o inv√°lida.")

# --- 3. L√ìGICA DE PREVIS√ÉO INTERATIVA (FLUXO CORRIGIDO) ---
while True:
    print("\n\n--- NOVA PREVIS√ÉO ANUAL ESTIMADA ---")

    # ETAPA 1: PEDIR O ANO (OBRIGAT√ìRIO)
    while True:
        try:
            ano_desejado = int(input("\nDigite o ANO para a previs√£o (Obrigat√≥rio, ex: 2026): "))
            if ano_desejado > df['Ano'].max():
                break
            else:
                print(f"Por favor, digite um ano futuro, maior que {df['Ano'].max()}.")
        except ValueError:
            print("Entrada inv√°lida. Por favor, digite um n√∫mero inteiro.")

    # ETAPA 2: PEDIR OS FILTROS (OPCIONAIS)
    df_filtrado = df.copy()
    filtros_aplicados = {}
    colunas_para_filtrar = ['uf', 'evento', 'arma', 'faixa_etaria']
    for coluna in colunas_para_filtrar:
        escolha = obter_filtro_usuario(df_filtrado, coluna, coluna.replace('_', ' ').title())
        if escolha:
            filtros_aplicados[coluna] = escolha
            df_filtrado = df_filtrado[df_filtrado[coluna] == escolha]

    # ETAPA 3: PREPARAR DADOS E FAZER A PREVIS√ÉO
    janela = 10
    if len(df_filtrado) < janela:
        print(f"\n‚ùå ERRO: N√£o h√° dados hist√≥ricos suficientes ({len(df_filtrado)} eventos) para o cen√°rio escolhido.")
    else:
        # Calcular a m√©dia de eventos por ano para o cen√°rio filtrado
        num_anos_historico = df_filtrado['Ano'].nunique()
        media_eventos_ano = len(df_filtrado) / num_anos_historico if num_anos_historico > 0 else 0

        # Montar a sequ√™ncia de entrada para o modelo
        # Pegamos os √∫ltimos 9 eventos reais e criamos um 10¬∫ evento "fict√≠cio" no ano desejado
        sequencia_base = df_filtrado.tail(janela - 1).copy()
        evento_futuro_template = df_filtrado.tail(1).copy()
        evento_futuro_template['Ano'] = ano_desejado

        sequencia_final_df = pd.concat([sequencia_base, evento_futuro_template], ignore_index=True)

        # Preparar os dados para o modelo usando o preprocessor carregado
        X_para_prever = sequencia_final_df.drop(columns=['total_vitima', 'data_referencia', 'municipio'])
        X_processado = preprocessor.transform(X_para_prever)
        X_final = np.reshape(X_processado, (1, X_processado.shape[0], X_processado.shape[1]))

        # Fazer a previs√£o para um evento t√≠pico no futuro
        previsao_evento_normalizada = model.predict(X_final)
        previsao_evento_real = y_scaler.inverse_transform(previsao_evento_normalizada)
        vitimas_por_evento = np.ceil(previsao_evento_real[0][0])

        # Calcular o total anual estimado
        previsao_anual_total = vitimas_por_evento * media_eventos_ano

        # ETAPA 4: MOSTRAR O RESULTADO FINAL
        print("\n-------------------------------------------")
        print("Cen√°rio da Previs√£o:")
        print(f"- Ano Previsto: {ano_desejado}")
        for nome, valor in filtros_aplicados.items():
            print(f"- {nome.title()}: {valor}")
        if not filtros_aplicados:
            print("- Nenhum filtro adicional (cen√°rio geral).")

        print("\nüéØ PREVIS√ÉO ANUAL ESTIMADA:")
        print(f"O total de v√≠timas estimado para o ano de {ano_desejado} neste cen√°rio √© de: {int(previsao_anual_total)}")
        print("-------------------------------------------")
        print(f"(Nota: Estimativa baseada em uma previs√£o de {int(vitimas_por_evento)} v√≠timas por evento, multiplicada pela m√©dia de {media_eventos_ano:.1f} eventos por ano para este cen√°rio).")

    if input("\nDeseja fazer uma nova previs√£o? (s/n): ").lower() != 's':
        break

print("\nScript de previs√£o finalizado.")